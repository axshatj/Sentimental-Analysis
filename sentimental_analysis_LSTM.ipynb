{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Mounting google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "bgN__vcZbHXb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57dea7ea-06c0-4f08-931f-0405b8fc23a0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "UH3SOaDLbeXK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a6ed1b9-cfc1-4cbe-ea13-14b69441b229"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing essential libraries and functions\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from numpy import array\n",
        "import csv\n",
        "from keras.preprocessing.text import one_hot, Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "# from keras.layers.core import Activation, Dropout, Dense\n",
        "from tensorflow.keras.layers import Activation, Dense, Dropout\n",
        "from keras.layers import Flatten, GlobalMaxPooling1D, Embedding, Conv1D, LSTM\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "X1iCpGAZbgJK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing IMDb Movie Reviews dataset\n",
        "movie_reviews = pd.read_csv(\"a1_IMDB_Dataset.csv\", on_bad_lines='skip', engine=\"python\")"
      ],
      "metadata": {
        "id": "jxYpq2AsbtPE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset exploration\n",
        "movie_reviews.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trVmTvgzbvSc",
        "outputId": "f2713a69-c33e-4483-87b5-6ca098cbc1c2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13418, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "movie_reviews.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "3WkXU4rUbw_-",
        "outputId": "cf12e51c-b0a4-4c27-ba74-c1982866ae67"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f7d8ad2f-e8bc-4922-9111-6ae43cac98af\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f7d8ad2f-e8bc-4922-9111-6ae43cac98af')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f7d8ad2f-e8bc-4922-9111-6ae43cac98af button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f7d8ad2f-e8bc-4922-9111-6ae43cac98af');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-081d43a0-02bc-4ae2-9972-c1354ffe5ba8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-081d43a0-02bc-4ae2-9972-c1354ffe5ba8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-081d43a0-02bc-4ae2-9972-c1354ffe5ba8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "movie_reviews",
              "summary": "{\n  \"name\": \"movie_reviews\",\n  \"rows\": 13418,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 13388,\n        \"samples\": [\n          \"I had the distinct displeasure of seeing this movie at the 2006 Vancouver International Film Festival. I have been attending this festival for over 5 years, and I have certainly seen some poor movies on occasion. However, 'First Bite' has reached a brand new low in film. In spite of being shot in beautiful locations, with the occasional, exquisite close up of fabulous food, the movie contorts an excessive number of plot twists and stilted characters until I was practically begging for it to end.<br /><br />The lead actor, David La Haye, completely failed to show any character development throughout the movie, portraying a pompous chef from beginning to end. Additional sub-plots, such as eating disorders, were developed so poorly and completely did not fit within any context that the movie had shown up to that point.<br /><br />A theme of mysticism was used as a poor attempt to conceal a movie that achieves nothing, goes nowhere, and completely disappoints.\",\n          \"This is an excellent Anderson production worth comparing with the best episodes of UFO or SPACE 1999 (first series). Of course it isn't some SFX extravaganza or Star Wars pseudo-mystic tripe fest, but a subtle movie that has a slow pace, yet it conveys the creepy, eerie and uncanny atmosphere of the best Anderson productions: for lovers of 'cerebral' sci-fi. Lynn Loring's voice is ABSOLUTELY AWFUL. SFX are good for this kind of product and acting is good as well. Two astronauts visit a planet on the opposite side of the sun but crash land home instead...or do they? Ah, videophones! Every now and then peddled as the next 'everyone's gadget next decade' but still to happen 40 years later. The device of Earth's twin planet on the opposite side of the sun also returns in Gamera tai daiakuju Giron (1969), so who copied whom?\",\n          \"Good historical drama which is very educational and also very entertaining to people who like history.Very good acting and script.Not as sensual and sexy as it is sometimes marketed,be prepared to peek into the pioneer spirit and human ability to adjust.Very touching as well for the spiritually mature. Not for people who do not like to think......\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"negative\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for missing values\n",
        "movie_reviews.isnull().values.any()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEcWLK0Rbyfh",
        "outputId": "9308117c-70e5-4d43-ce48-363de9d4f385"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's observe distribution of positive / negative sentiments in dataset\n",
        "import seaborn as sns\n",
        "sns.countplot(x='sentiment', data=movie_reviews)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "81WZRIGWbz5K",
        "outputId": "436a1514-7541-47df-edad-7022832208f5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='sentiment', ylabel='count'>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#un-processed raw text\n",
        "movie_reviews[\"review\"][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "n75JsOy2b1jE",
        "outputId": "fa8f4ff2-5dbf-427d-94c3-0750892b408c"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#removing HTML tags\n",
        "TAG_RE = re.compile(r'<[^>]+>')\n",
        "\n",
        "def remove_tags(text):\n",
        "    '''Removes HTML tags: replaces anything between opening and closing <> with empty space'''\n",
        "\n",
        "    return TAG_RE.sub('', text)"
      ],
      "metadata": {
        "id": "IWVyIJnyb27w"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VNNtLM_b4bR",
        "outputId": "07f06842-fdb3-4f5a-c896-9f4932b58ac5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Pre-processing text\n",
        "def preprocess_text(sen):\n",
        "    '''Cleans text data up, leaving only 2 or more char long non-stepwords composed of A-Z & a-z only\n",
        "    in lowercase'''\n",
        "\n",
        "    sentence = sen.lower()\n",
        "\n",
        "    # Remove html tags\n",
        "    sentence = remove_tags(sentence)\n",
        "\n",
        "    # Remove punctuations and numbers\n",
        "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
        "\n",
        "    # Single character removal\n",
        "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)  # When we remove apostrophe from the word \"Mark's\", the apostrophe is replaced by an empty space. Hence, we are left with single character \"s\" that we are removing here.\n",
        "\n",
        "    # Remove multiple spaces\n",
        "    sentence = re.sub(r'\\s+', ' ', sentence)  # Next, we remove all the single characters and replace it by a space which creates multiple spaces in our text. Finally, we remove the multiple spaces from our text as well.\n",
        "\n",
        "    # Remove Stopwords\n",
        "    pattern = re.compile(r'\\b(' + r'|'.join(stopwords.words('english')) + r')\\b\\s*')\n",
        "    sentence = pattern.sub('', sentence)\n",
        "\n",
        "    return sentence"
      ],
      "metadata": {
        "id": "QATEBTZTb571"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calling preprocessing_text function on movie_reviews\n",
        "X = []\n",
        "sentences = list(movie_reviews['review'])\n",
        "for sen in sentences:\n",
        "    X.append(preprocess_text(sen))"
      ],
      "metadata": {
        "id": "GWzoA-Aob7oL"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample cleaned up movie review\n",
        "X[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "DhKitNHcb9G9",
        "outputId": "6ae8219d-b2a6-4cf2-9890-598a5d599c4a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'thought wonderful way spend time hot summer weekend sitting air conditioned theater watching light hearted comedy plot simplistic dialogue witty characters likable even well bread suspected serial killer may disappointed realize match point risk addiction thought proof woody allen still fully control style many us grown love laughed one woody comedies years dare say decade never impressed scarlet johanson managed tone sexy image jumped right average spirited young woman may crown jewel career wittier devil wears prada interesting superman great comedy go see friends '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting sentiment labels to 0 & 1\n",
        "y = movie_reviews['sentiment']\n",
        "\n",
        "y = np.array(list(map(lambda x: 1 if x==\"positive\" else 0, y)))"
      ],
      "metadata": {
        "id": "1jj_nGzfb-xK"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#splitting into training and testing dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n"
      ],
      "metadata": {
        "id": "OvqRg7UgcAa9"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Embedding layer expects the words to be in numeric form\n",
        "# Using Tokenizer function from keras.preprocessing.text library\n",
        "# Method fit_on_text trains the tokenizer\n",
        "# Method texts_to_sequences converts sentences to their numeric form\n",
        "word_tokenizer = Tokenizer()\n",
        "word_tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train = word_tokenizer.texts_to_sequences(X_train)\n",
        "X_test = word_tokenizer.texts_to_sequences(X_test)"
      ],
      "metadata": {
        "id": "O7xbJaQxcB5C"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding 1 to store dimensions for words for which no pretrained word embeddings exist\n",
        "vocab_length = len(word_tokenizer.word_index) + 1\n",
        "\n",
        "vocab_length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-IwbTfccDaC",
        "outputId": "6beb804c-81dd-48fd-9919-e314384e5aae"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "53647"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Padding all reviews to fixed length 100\n",
        "maxlen = 100\n",
        "\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
      ],
      "metadata": {
        "id": "TOn7WGkmcFOf"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load GloVe word embeddings and create an Embeddings Dictionary\n",
        "from numpy import asarray\n",
        "from numpy import zeros\n",
        "\n",
        "embeddings_dictionary = dict()\n",
        "glove_file = open('a2_glove.6B.100d.txt', encoding=\"utf8\")\n",
        "\n",
        "target_length = 100\n",
        "for line in glove_file:\n",
        "    records = line.split()\n",
        "    word = records[0]\n",
        "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
        "    embeddings_dictionary [word] = vector_dimensions\n",
        "glove_file.close()"
      ],
      "metadata": {
        "id": "SQGATjnMcGzQ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Embedding Matrix having 100 columns\n",
        "# Containing 100-dimensional GloVe word embeddings for all words in our corpus.\n",
        "embedding_matrix = zeros((vocab_length, 100))\n",
        "for word, index in word_tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings_dictionary.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[index] = embedding_vector"
      ],
      "metadata": {
        "id": "hRFz2MHhcIno"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTkTnjGUcKbs",
        "outputId": "99dbe407-9f0a-4baa-a16c-f92a6b4796ad"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(53647, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import LSTM"
      ],
      "metadata": {
        "id": "AdlKxJmecNA_"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural Network architecture\n",
        "lstm_model = Sequential()\n",
        "embedding_layer = Embedding(vocab_length, 100, weights=[embedding_matrix], input_length=maxlen , trainable=False)\n",
        "\n",
        "lstm_model.add(embedding_layer)\n",
        "lstm_model.add(LSTM(128))\n",
        "\n",
        "lstm_model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "tXT3UGEncOeH"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model compiling\n",
        "lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "print(lstm_model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqCzSmX9cPzy",
        "outputId": "c6ca7fd9-4f4e-4122-965a-b573e3cbb02d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 100, 100)          5364700   \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 128)               117248    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5482077 (20.91 MB)\n",
            "Trainable params: 117377 (458.50 KB)\n",
            "Non-trainable params: 5364700 (20.46 MB)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Training\n",
        "lstm_model_history = lstm_model.fit(X_train, y_train, batch_size=128, epochs=10, verbose=1, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0XbOZGdcRL3",
        "outputId": "1b4f7931-aa00-43d9-894e-b6169818ead0"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "68/68 [==============================] - 25s 369ms/step - loss: 0.3781 - acc: 0.8375 - val_loss: 0.4452 - val_acc: 0.8058\n",
            "Epoch 2/10\n",
            "68/68 [==============================] - 28s 417ms/step - loss: 0.3575 - acc: 0.8424 - val_loss: 0.4367 - val_acc: 0.8160\n",
            "Epoch 3/10\n",
            "68/68 [==============================] - 29s 435ms/step - loss: 0.3516 - acc: 0.8471 - val_loss: 0.4161 - val_acc: 0.8156\n",
            "Epoch 4/10\n",
            "68/68 [==============================] - 27s 397ms/step - loss: 0.3356 - acc: 0.8636 - val_loss: 0.4078 - val_acc: 0.8249\n",
            "Epoch 5/10\n",
            "68/68 [==============================] - 34s 499ms/step - loss: 0.3161 - acc: 0.8676 - val_loss: 0.3786 - val_acc: 0.8365\n",
            "Epoch 6/10\n",
            "68/68 [==============================] - 31s 463ms/step - loss: 0.3021 - acc: 0.8778 - val_loss: 0.3722 - val_acc: 0.8402\n",
            "Epoch 7/10\n",
            "68/68 [==============================] - 32s 465ms/step - loss: 0.2796 - acc: 0.8875 - val_loss: 0.3869 - val_acc: 0.8407\n",
            "Epoch 8/10\n",
            "68/68 [==============================] - 33s 479ms/step - loss: 0.2432 - acc: 0.9046 - val_loss: 0.4478 - val_acc: 0.8309\n",
            "Epoch 9/10\n",
            "68/68 [==============================] - 34s 497ms/step - loss: 0.2369 - acc: 0.9072 - val_loss: 0.4142 - val_acc: 0.8444\n",
            "Epoch 10/10\n",
            "68/68 [==============================] - 24s 354ms/step - loss: 0.2357 - acc: 0.9117 - val_loss: 0.4052 - val_acc: 0.8356\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions on the Test Set\n",
        "score = lstm_model.evaluate(X_test, y_test, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zP6yZk8rcSrI",
        "outputId": "123f5136-fba2-4f7c-da3c-02a4fef46fd3"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "84/84 [==============================] - 4s 49ms/step - loss: 0.3957 - acc: 0.8290\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# Assuming vocab_length, maxlen, X_train, y_train, X_test, y_test, and embedding_matrix are predefined\n",
        "\n",
        "def create_model():\n",
        "    model = Sequential()\n",
        "    embedding_layer = Embedding(vocab_length, 100, weights=[embedding_matrix], input_length=maxlen, trainable=False)\n",
        "    model.add(embedding_layer)\n",
        "    model.add(LSTM(128))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "    return model\n",
        "\n",
        "# Define the range of epochs to try\n",
        "epoch_values = [10, 20, 30, 40, 50]\n",
        "best_epoch = 0\n",
        "best_val_acc = 0.0\n",
        "\n",
        "for epochs in epoch_values:\n",
        "    print(f\"\\nTraining model with {epochs} epochs...\\n\")\n",
        "\n",
        "    model = create_model()\n",
        "\n",
        "    # Early stopping callback to prevent overfitting\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "    history = model.fit(X_train, y_train, batch_size=128, epochs=epochs, verbose=1, validation_split=0.2, callbacks=[early_stopping])\n",
        "\n",
        "    val_acc = max(history.history['val_acc'])\n",
        "\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        best_epoch = epochs\n",
        "\n",
        "    print(f\"Finished training with {epochs} epochs. Best validation accuracy: {val_acc}\")\n",
        "\n",
        "print(f\"\\nBest number of epochs: {best_epoch} with validation accuracy: {best_val_acc}\")\n",
        "\n",
        "# Train final model with the best number of epochs\n",
        "final_model = create_model()\n",
        "final_model.fit(X_train, y_train, batch_size=128, epochs=best_epoch, verbose=1, validation_split=0.2)\n",
        "\n",
        "# Evaluate the final model on the test set\n",
        "score = final_model.evaluate(X_test, y_test, verbose=1)\n",
        "print(f\"\\nTest Loss: {score[0]}\")\n",
        "print(f\"Test Accuracy: {score[1]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fst8SCzhjIIb",
        "outputId": "6298c7ce-e1bb-47ac-f6be-cd0e3908a4b8"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training model with 10 epochs...\n",
            "\n",
            "Epoch 1/10\n",
            "68/68 [==============================] - 29s 382ms/step - loss: 0.6319 - acc: 0.6485 - val_loss: 0.5610 - val_acc: 0.7513\n",
            "Epoch 2/10\n",
            "68/68 [==============================] - 23s 342ms/step - loss: 0.5141 - acc: 0.7687 - val_loss: 0.4920 - val_acc: 0.7834\n",
            "Epoch 3/10\n",
            "68/68 [==============================] - 23s 346ms/step - loss: 0.4633 - acc: 0.7924 - val_loss: 0.4758 - val_acc: 0.7923\n",
            "Epoch 4/10\n",
            "68/68 [==============================] - 25s 374ms/step - loss: 0.4534 - acc: 0.8014 - val_loss: 0.4471 - val_acc: 0.7946\n",
            "Epoch 5/10\n",
            "68/68 [==============================] - 23s 336ms/step - loss: 0.4224 - acc: 0.8138 - val_loss: 0.4542 - val_acc: 0.7881\n",
            "Epoch 6/10\n",
            "68/68 [==============================] - 28s 420ms/step - loss: 0.4131 - acc: 0.8230 - val_loss: 0.4314 - val_acc: 0.8090\n",
            "Epoch 7/10\n",
            "68/68 [==============================] - 25s 360ms/step - loss: 0.3764 - acc: 0.8375 - val_loss: 0.4083 - val_acc: 0.8277\n",
            "Epoch 8/10\n",
            "68/68 [==============================] - 23s 346ms/step - loss: 0.3740 - acc: 0.8396 - val_loss: 0.4105 - val_acc: 0.8314\n",
            "Epoch 9/10\n",
            "68/68 [==============================] - 26s 385ms/step - loss: 0.3362 - acc: 0.8596 - val_loss: 0.4004 - val_acc: 0.8128\n",
            "Epoch 10/10\n",
            "68/68 [==============================] - 24s 348ms/step - loss: 0.3251 - acc: 0.8634 - val_loss: 0.4304 - val_acc: 0.8016\n",
            "Finished training with 10 epochs. Best validation accuracy: 0.8313926458358765\n",
            "\n",
            "Training model with 20 epochs...\n",
            "\n",
            "Epoch 1/20\n",
            "68/68 [==============================] - 29s 399ms/step - loss: 0.6137 - acc: 0.6595 - val_loss: 0.5178 - val_acc: 0.7587\n",
            "Epoch 2/20\n",
            "68/68 [==============================] - 24s 346ms/step - loss: 0.5113 - acc: 0.7680 - val_loss: 0.4912 - val_acc: 0.7718\n",
            "Epoch 3/20\n",
            "68/68 [==============================] - 23s 346ms/step - loss: 0.4672 - acc: 0.7901 - val_loss: 0.5053 - val_acc: 0.7690\n",
            "Epoch 4/20\n",
            "68/68 [==============================] - 29s 423ms/step - loss: 0.4509 - acc: 0.8026 - val_loss: 0.4345 - val_acc: 0.8081\n",
            "Epoch 5/20\n",
            "68/68 [==============================] - 24s 349ms/step - loss: 0.4285 - acc: 0.8110 - val_loss: 0.4708 - val_acc: 0.8146\n",
            "Epoch 6/20\n",
            "68/68 [==============================] - 23s 347ms/step - loss: 0.4026 - acc: 0.8256 - val_loss: 0.4239 - val_acc: 0.8211\n",
            "Epoch 7/20\n",
            "68/68 [==============================] - 26s 389ms/step - loss: 0.3799 - acc: 0.8353 - val_loss: 0.4238 - val_acc: 0.8114\n",
            "Epoch 8/20\n",
            "68/68 [==============================] - 24s 349ms/step - loss: 0.3720 - acc: 0.8388 - val_loss: 0.4219 - val_acc: 0.8179\n",
            "Epoch 9/20\n",
            "68/68 [==============================] - 23s 343ms/step - loss: 0.3524 - acc: 0.8542 - val_loss: 0.5255 - val_acc: 0.7965\n",
            "Epoch 10/20\n",
            "68/68 [==============================] - 28s 409ms/step - loss: 0.3475 - acc: 0.8538 - val_loss: 0.4282 - val_acc: 0.8020\n",
            "Epoch 11/20\n",
            "68/68 [==============================] - 23s 335ms/step - loss: 0.3279 - acc: 0.8603 - val_loss: 0.3928 - val_acc: 0.8277\n",
            "Epoch 12/20\n",
            "68/68 [==============================] - 23s 341ms/step - loss: 0.3163 - acc: 0.8655 - val_loss: 0.4278 - val_acc: 0.8072\n",
            "Epoch 13/20\n",
            "68/68 [==============================] - 30s 443ms/step - loss: 0.2893 - acc: 0.8825 - val_loss: 0.4756 - val_acc: 0.8216\n",
            "Epoch 14/20\n",
            "68/68 [==============================] - 23s 337ms/step - loss: 0.2625 - acc: 0.8988 - val_loss: 0.3767 - val_acc: 0.8374\n",
            "Epoch 15/20\n",
            "68/68 [==============================] - 25s 365ms/step - loss: 0.2388 - acc: 0.9082 - val_loss: 0.4178 - val_acc: 0.8351\n",
            "Epoch 16/20\n",
            "68/68 [==============================] - 24s 354ms/step - loss: 0.2398 - acc: 0.9077 - val_loss: 0.4318 - val_acc: 0.8211\n",
            "Epoch 17/20\n",
            "68/68 [==============================] - 24s 349ms/step - loss: 0.2012 - acc: 0.9261 - val_loss: 0.4030 - val_acc: 0.8407\n",
            "Epoch 18/20\n",
            "68/68 [==============================] - 26s 390ms/step - loss: 0.1972 - acc: 0.9281 - val_loss: 0.4123 - val_acc: 0.8402\n",
            "Epoch 19/20\n",
            "68/68 [==============================] - 24s 349ms/step - loss: 0.1849 - acc: 0.9336 - val_loss: 0.4267 - val_acc: 0.8230\n",
            "Finished training with 20 epochs. Best validation accuracy: 0.8407079577445984\n",
            "\n",
            "Training model with 30 epochs...\n",
            "\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 32s 444ms/step - loss: 0.6264 - acc: 0.6428 - val_loss: 0.5611 - val_acc: 0.7452\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 27s 402ms/step - loss: 0.5267 - acc: 0.7542 - val_loss: 0.4813 - val_acc: 0.7769\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 23s 342ms/step - loss: 0.4682 - acc: 0.7864 - val_loss: 0.4979 - val_acc: 0.7909\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 26s 379ms/step - loss: 0.4501 - acc: 0.8042 - val_loss: 0.4301 - val_acc: 0.8118\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 23s 336ms/step - loss: 0.4240 - acc: 0.8129 - val_loss: 0.4592 - val_acc: 0.8118\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 22s 329ms/step - loss: 0.4168 - acc: 0.8207 - val_loss: 0.4133 - val_acc: 0.8197\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 27s 397ms/step - loss: 0.4029 - acc: 0.8290 - val_loss: 0.4011 - val_acc: 0.8235\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 23s 338ms/step - loss: 0.3673 - acc: 0.8451 - val_loss: 0.3991 - val_acc: 0.8263\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 22s 330ms/step - loss: 0.3414 - acc: 0.8538 - val_loss: 0.3976 - val_acc: 0.8202\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 30s 436ms/step - loss: 0.3337 - acc: 0.8572 - val_loss: 0.4053 - val_acc: 0.8104\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 23s 341ms/step - loss: 0.3069 - acc: 0.8727 - val_loss: 0.3854 - val_acc: 0.8361\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 27s 393ms/step - loss: 0.2906 - acc: 0.8832 - val_loss: 0.4119 - val_acc: 0.8291\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 23s 342ms/step - loss: 0.2673 - acc: 0.8936 - val_loss: 0.3906 - val_acc: 0.8402\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 23s 341ms/step - loss: 0.2676 - acc: 0.8952 - val_loss: 0.4291 - val_acc: 0.8239\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 27s 403ms/step - loss: 0.2307 - acc: 0.9116 - val_loss: 0.4220 - val_acc: 0.8123\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 22s 329ms/step - loss: 0.2035 - acc: 0.9241 - val_loss: 0.3969 - val_acc: 0.8281\n",
            "Finished training with 30 epochs. Best validation accuracy: 0.8402422070503235\n",
            "\n",
            "Training model with 40 epochs...\n",
            "\n",
            "Epoch 1/40\n",
            "68/68 [==============================] - 30s 401ms/step - loss: 0.6404 - acc: 0.6250 - val_loss: 0.5250 - val_acc: 0.7657\n",
            "Epoch 2/40\n",
            "68/68 [==============================] - 25s 363ms/step - loss: 0.5236 - acc: 0.7624 - val_loss: 0.4879 - val_acc: 0.7816\n",
            "Epoch 3/40\n",
            "68/68 [==============================] - 24s 349ms/step - loss: 0.4637 - acc: 0.7919 - val_loss: 0.4710 - val_acc: 0.7811\n",
            "Epoch 4/40\n",
            "68/68 [==============================] - 28s 412ms/step - loss: 0.4301 - acc: 0.8103 - val_loss: 0.4272 - val_acc: 0.8114\n",
            "Epoch 5/40\n",
            "68/68 [==============================] - 24s 349ms/step - loss: 0.4112 - acc: 0.8209 - val_loss: 0.4516 - val_acc: 0.8100\n",
            "Epoch 6/40\n",
            "68/68 [==============================] - 26s 387ms/step - loss: 0.4126 - acc: 0.8224 - val_loss: 0.4123 - val_acc: 0.8197\n",
            "Epoch 7/40\n",
            "68/68 [==============================] - 24s 344ms/step - loss: 0.3727 - acc: 0.8338 - val_loss: 0.4152 - val_acc: 0.8202\n",
            "Epoch 8/40\n",
            "68/68 [==============================] - 23s 340ms/step - loss: 0.3789 - acc: 0.8407 - val_loss: 0.4207 - val_acc: 0.8016\n",
            "Epoch 9/40\n",
            "68/68 [==============================] - 30s 449ms/step - loss: 0.3383 - acc: 0.8597 - val_loss: 0.3832 - val_acc: 0.8286\n",
            "Epoch 10/40\n",
            "68/68 [==============================] - 24s 353ms/step - loss: 0.3188 - acc: 0.8703 - val_loss: 0.4321 - val_acc: 0.8398\n",
            "Epoch 11/40\n",
            "68/68 [==============================] - 24s 348ms/step - loss: 0.3129 - acc: 0.8741 - val_loss: 0.4117 - val_acc: 0.8267\n",
            "Epoch 12/40\n",
            "68/68 [==============================] - 26s 379ms/step - loss: 0.2977 - acc: 0.8804 - val_loss: 0.4551 - val_acc: 0.8244\n",
            "Epoch 13/40\n",
            "68/68 [==============================] - 23s 338ms/step - loss: 0.2783 - acc: 0.8888 - val_loss: 0.4196 - val_acc: 0.8407\n",
            "Epoch 14/40\n",
            "68/68 [==============================] - 23s 341ms/step - loss: 0.2645 - acc: 0.8958 - val_loss: 0.4114 - val_acc: 0.8393\n",
            "Finished training with 40 epochs. Best validation accuracy: 0.8407079577445984\n",
            "\n",
            "Training model with 50 epochs...\n",
            "\n",
            "Epoch 1/50\n",
            "68/68 [==============================] - 27s 354ms/step - loss: 0.6223 - acc: 0.6413 - val_loss: 0.5441 - val_acc: 0.7336\n",
            "Epoch 2/50\n",
            "68/68 [==============================] - 27s 406ms/step - loss: 0.5474 - acc: 0.7405 - val_loss: 0.5017 - val_acc: 0.7732\n",
            "Epoch 3/50\n",
            "68/68 [==============================] - 26s 381ms/step - loss: 0.4702 - acc: 0.7865 - val_loss: 0.4542 - val_acc: 0.7881\n",
            "Epoch 4/50\n",
            "68/68 [==============================] - 24s 350ms/step - loss: 0.4533 - acc: 0.7938 - val_loss: 0.4864 - val_acc: 0.7965\n",
            "Epoch 5/50\n",
            "68/68 [==============================] - 27s 395ms/step - loss: 0.4230 - acc: 0.8113 - val_loss: 0.4182 - val_acc: 0.8132\n",
            "Epoch 6/50\n",
            "68/68 [==============================] - 24s 351ms/step - loss: 0.3993 - acc: 0.8307 - val_loss: 0.5035 - val_acc: 0.7671\n",
            "Epoch 7/50\n",
            "68/68 [==============================] - 24s 351ms/step - loss: 0.4012 - acc: 0.8233 - val_loss: 0.4123 - val_acc: 0.8272\n",
            "Epoch 8/50\n",
            "68/68 [==============================] - 28s 415ms/step - loss: 0.3591 - acc: 0.8445 - val_loss: 0.4251 - val_acc: 0.8118\n",
            "Epoch 9/50\n",
            "68/68 [==============================] - 24s 353ms/step - loss: 0.3723 - acc: 0.8410 - val_loss: 0.4008 - val_acc: 0.8365\n",
            "Epoch 10/50\n",
            "68/68 [==============================] - 24s 358ms/step - loss: 0.3395 - acc: 0.8597 - val_loss: 0.3918 - val_acc: 0.8361\n",
            "Epoch 11/50\n",
            "68/68 [==============================] - 29s 432ms/step - loss: 0.3173 - acc: 0.8651 - val_loss: 0.3776 - val_acc: 0.8421\n",
            "Epoch 12/50\n",
            "68/68 [==============================] - 23s 340ms/step - loss: 0.2994 - acc: 0.8771 - val_loss: 0.4058 - val_acc: 0.8426\n",
            "Epoch 13/50\n",
            "68/68 [==============================] - 26s 388ms/step - loss: 0.2913 - acc: 0.8832 - val_loss: 0.3995 - val_acc: 0.8267\n",
            "Epoch 14/50\n",
            "68/68 [==============================] - 24s 352ms/step - loss: 0.2642 - acc: 0.8929 - val_loss: 0.3974 - val_acc: 0.8197\n",
            "Epoch 15/50\n",
            "68/68 [==============================] - 24s 352ms/step - loss: 0.2484 - acc: 0.9033 - val_loss: 0.4118 - val_acc: 0.8281\n",
            "Epoch 16/50\n",
            "68/68 [==============================] - 26s 388ms/step - loss: 0.2287 - acc: 0.9116 - val_loss: 0.4400 - val_acc: 0.8337\n",
            "Finished training with 50 epochs. Best validation accuracy: 0.8425710201263428\n",
            "\n",
            "Best number of epochs: 50 with validation accuracy: 0.8425710201263428\n",
            "Epoch 1/50\n",
            "68/68 [==============================] - 28s 380ms/step - loss: 0.6080 - acc: 0.6639 - val_loss: 0.4950 - val_acc: 0.7769\n",
            "Epoch 2/50\n",
            "68/68 [==============================] - 29s 429ms/step - loss: 0.5041 - acc: 0.7649 - val_loss: 0.5020 - val_acc: 0.7634\n",
            "Epoch 3/50\n",
            "68/68 [==============================] - 24s 350ms/step - loss: 0.4695 - acc: 0.7841 - val_loss: 0.4535 - val_acc: 0.8011\n",
            "Epoch 4/50\n",
            "68/68 [==============================] - 26s 388ms/step - loss: 0.4314 - acc: 0.8103 - val_loss: 0.4276 - val_acc: 0.8090\n",
            "Epoch 5/50\n",
            "68/68 [==============================] - 23s 344ms/step - loss: 0.4203 - acc: 0.8180 - val_loss: 0.4246 - val_acc: 0.8174\n",
            "Epoch 6/50\n",
            "68/68 [==============================] - 24s 353ms/step - loss: 0.3903 - acc: 0.8296 - val_loss: 0.4315 - val_acc: 0.7960\n",
            "Epoch 7/50\n",
            "68/68 [==============================] - 26s 379ms/step - loss: 0.3807 - acc: 0.8318 - val_loss: 0.4267 - val_acc: 0.8090\n",
            "Epoch 8/50\n",
            "68/68 [==============================] - 24s 356ms/step - loss: 0.3572 - acc: 0.8483 - val_loss: 0.3976 - val_acc: 0.8156\n",
            "Epoch 9/50\n",
            "68/68 [==============================] - 23s 341ms/step - loss: 0.3407 - acc: 0.8551 - val_loss: 0.3981 - val_acc: 0.8295\n",
            "Epoch 10/50\n",
            "68/68 [==============================] - 30s 450ms/step - loss: 0.3182 - acc: 0.8651 - val_loss: 0.4526 - val_acc: 0.8160\n",
            "Epoch 11/50\n",
            "68/68 [==============================] - 25s 362ms/step - loss: 0.3065 - acc: 0.8716 - val_loss: 0.4572 - val_acc: 0.8151\n",
            "Epoch 12/50\n",
            "68/68 [==============================] - 24s 352ms/step - loss: 0.3082 - acc: 0.8699 - val_loss: 0.4149 - val_acc: 0.8244\n",
            "Epoch 13/50\n",
            "68/68 [==============================] - 27s 403ms/step - loss: 0.3035 - acc: 0.8752 - val_loss: 0.4697 - val_acc: 0.8263\n",
            "Epoch 14/50\n",
            "68/68 [==============================] - 24s 345ms/step - loss: 0.2700 - acc: 0.8909 - val_loss: 0.4479 - val_acc: 0.8319\n",
            "Epoch 15/50\n",
            "68/68 [==============================] - 23s 344ms/step - loss: 0.2419 - acc: 0.9046 - val_loss: 0.3688 - val_acc: 0.8421\n",
            "Epoch 16/50\n",
            "68/68 [==============================] - 25s 362ms/step - loss: 0.2326 - acc: 0.9145 - val_loss: 0.3857 - val_acc: 0.8314\n",
            "Epoch 17/50\n",
            "68/68 [==============================] - 26s 380ms/step - loss: 0.2519 - acc: 0.9022 - val_loss: 0.4531 - val_acc: 0.8011\n",
            "Epoch 18/50\n",
            "68/68 [==============================] - 23s 341ms/step - loss: 0.2096 - acc: 0.9185 - val_loss: 0.5073 - val_acc: 0.8402\n",
            "Epoch 19/50\n",
            "68/68 [==============================] - 27s 402ms/step - loss: 0.1944 - acc: 0.9306 - val_loss: 0.4350 - val_acc: 0.8323\n",
            "Epoch 20/50\n",
            "68/68 [==============================] - 24s 355ms/step - loss: 0.1553 - acc: 0.9462 - val_loss: 0.4481 - val_acc: 0.8412\n",
            "Epoch 21/50\n",
            "68/68 [==============================] - 28s 409ms/step - loss: 0.1369 - acc: 0.9554 - val_loss: 0.5053 - val_acc: 0.8356\n",
            "Epoch 22/50\n",
            "68/68 [==============================] - 24s 352ms/step - loss: 0.1278 - acc: 0.9573 - val_loss: 0.4398 - val_acc: 0.8342\n",
            "Epoch 23/50\n",
            "68/68 [==============================] - 23s 345ms/step - loss: 0.1272 - acc: 0.9602 - val_loss: 0.5557 - val_acc: 0.8239\n",
            "Epoch 24/50\n",
            "68/68 [==============================] - 28s 410ms/step - loss: 0.1105 - acc: 0.9642 - val_loss: 0.5579 - val_acc: 0.8300\n",
            "Epoch 25/50\n",
            "68/68 [==============================] - 24s 352ms/step - loss: 0.1231 - acc: 0.9610 - val_loss: 0.4480 - val_acc: 0.8151\n",
            "Epoch 26/50\n",
            "68/68 [==============================] - 24s 352ms/step - loss: 0.1142 - acc: 0.9646 - val_loss: 0.4783 - val_acc: 0.8500\n",
            "Epoch 27/50\n",
            "68/68 [==============================] - 32s 471ms/step - loss: 0.0773 - acc: 0.9800 - val_loss: 0.5597 - val_acc: 0.8249\n",
            "Epoch 28/50\n",
            "68/68 [==============================] - 24s 352ms/step - loss: 0.1146 - acc: 0.9645 - val_loss: 0.5172 - val_acc: 0.8384\n",
            "Epoch 29/50\n",
            "68/68 [==============================] - 24s 347ms/step - loss: 0.0753 - acc: 0.9808 - val_loss: 0.5824 - val_acc: 0.8351\n",
            "Epoch 30/50\n",
            "68/68 [==============================] - 27s 389ms/step - loss: 0.0586 - acc: 0.9861 - val_loss: 0.5894 - val_acc: 0.8309\n",
            "Epoch 31/50\n",
            "68/68 [==============================] - 23s 341ms/step - loss: 0.0638 - acc: 0.9837 - val_loss: 0.6492 - val_acc: 0.8398\n",
            "Epoch 32/50\n",
            "68/68 [==============================] - 24s 351ms/step - loss: 0.0473 - acc: 0.9895 - val_loss: 0.7037 - val_acc: 0.8184\n",
            "Epoch 33/50\n",
            "68/68 [==============================] - 27s 403ms/step - loss: 0.0502 - acc: 0.9880 - val_loss: 0.5926 - val_acc: 0.8388\n",
            "Epoch 34/50\n",
            "68/68 [==============================] - 23s 343ms/step - loss: 0.0518 - acc: 0.9887 - val_loss: 0.6734 - val_acc: 0.8398\n",
            "Epoch 35/50\n",
            "68/68 [==============================] - 24s 353ms/step - loss: 0.0585 - acc: 0.9852 - val_loss: 0.6030 - val_acc: 0.8444\n",
            "Epoch 36/50\n",
            "68/68 [==============================] - 27s 397ms/step - loss: 0.0708 - acc: 0.9811 - val_loss: 0.7129 - val_acc: 0.8300\n",
            "Epoch 37/50\n",
            "68/68 [==============================] - 28s 414ms/step - loss: 0.0584 - acc: 0.9853 - val_loss: 0.6410 - val_acc: 0.8291\n",
            "Epoch 38/50\n",
            "68/68 [==============================] - 24s 356ms/step - loss: 0.0389 - acc: 0.9918 - val_loss: 0.7308 - val_acc: 0.8407\n",
            "Epoch 39/50\n",
            "68/68 [==============================] - 24s 356ms/step - loss: 0.0461 - acc: 0.9905 - val_loss: 0.6245 - val_acc: 0.8412\n",
            "Epoch 40/50\n",
            "68/68 [==============================] - 28s 416ms/step - loss: 0.0524 - acc: 0.9874 - val_loss: 0.7089 - val_acc: 0.8216\n",
            "Epoch 41/50\n",
            "68/68 [==============================] - 24s 354ms/step - loss: 0.0653 - acc: 0.9836 - val_loss: 0.5788 - val_acc: 0.8253\n",
            "Epoch 42/50\n",
            "68/68 [==============================] - 27s 396ms/step - loss: 0.0591 - acc: 0.9832 - val_loss: 0.7530 - val_acc: 0.8356\n",
            "Epoch 43/50\n",
            "68/68 [==============================] - 25s 362ms/step - loss: 0.0520 - acc: 0.9872 - val_loss: 0.7489 - val_acc: 0.8104\n",
            "Epoch 44/50\n",
            "68/68 [==============================] - 28s 408ms/step - loss: 0.0637 - acc: 0.9839 - val_loss: 0.6737 - val_acc: 0.8426\n",
            "Epoch 45/50\n",
            "68/68 [==============================] - 27s 393ms/step - loss: 0.1118 - acc: 0.9647 - val_loss: 0.6103 - val_acc: 0.8398\n",
            "Epoch 46/50\n",
            "68/68 [==============================] - 24s 353ms/step - loss: 0.0449 - acc: 0.9900 - val_loss: 0.6441 - val_acc: 0.8305\n",
            "Epoch 47/50\n",
            "68/68 [==============================] - 24s 352ms/step - loss: 0.0360 - acc: 0.9922 - val_loss: 0.6830 - val_acc: 0.8402\n",
            "Epoch 48/50\n",
            "68/68 [==============================] - 27s 396ms/step - loss: 0.0282 - acc: 0.9952 - val_loss: 0.7048 - val_acc: 0.8430\n",
            "Epoch 49/50\n",
            "68/68 [==============================] - 25s 363ms/step - loss: 0.0451 - acc: 0.9878 - val_loss: 0.6736 - val_acc: 0.7960\n",
            "Epoch 50/50\n",
            "68/68 [==============================] - 23s 344ms/step - loss: 0.0563 - acc: 0.9851 - val_loss: 0.7052 - val_acc: 0.8323\n",
            "84/84 [==============================] - 7s 84ms/step - loss: 0.7191 - acc: 0.8279\n",
            "\n",
            "Test Loss: 0.7190636992454529\n",
            "Test Accuracy: 0.8278688788414001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Performance\n",
        "print(\"Test Score:\", score[0])\n",
        "print(\"Test Accuracy:\", score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfQA-RrocUL9",
        "outputId": "ec566721-02ec-4691-fafd-3e90b00af7fa"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Score: 0.39567649364471436\n",
            "Test Accuracy: 0.8289865851402283\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}